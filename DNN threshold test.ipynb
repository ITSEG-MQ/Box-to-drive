{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Sensor Test\n",
    "## Angle Threshold - DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Aims：\n",
    "Test the influence of the threshold of different steer angles on the classification accuracy, and choose a suitable threshold of the steer angle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Design：\n",
    "For efficiency purposes, this experiment uses DNN to determine whether the current angle_threshold is reasonable.  \n",
    "If the accuracy rate of DNN is low, we believe that the current angle_threshold cannot separate left and right well. If the accuracy is high, we can regard the current angle_threshold is reasonable.  \n",
    "This experiment uses the KFold method of 4 Folds to reduce the influence of randomness in the separation of the training set and the test set on the results.\n",
    "\n",
    "This experiment tested the effect of angle_threshold of 10, 20, 30...90 on the rationality of splitting the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Content："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data, assign a label to each image data according to the threshold, including go, stop, left, right\n",
    "# The default speed_threshold=5, angle_threshold=30\n",
    "# Finally we generate bounding_box data: X, corresponding label: y\n",
    "import random\n",
    "def process_data(data, speed_threshold, angle_threshold, sign_threshold, data_size):\n",
    "    stop, go, left, right = split(data, speed_threshold, angle_threshold, sign_threshold, data_size)\n",
    "\n",
    "    print(\"go, stop, left, right\")\n",
    "    print(len(go), len(stop), len(left), len(right) )\n",
    "\n",
    "    X = np.array(list(go)+list(stop)+list(left)+list(right))\n",
    "    y = np.array(list(np.ones(len(go)))+list(np.ones(len(stop))*2)+list(np.ones(len(left))*3)+list(np.ones(len(right))*4))\n",
    "    \n",
    "    mask = [i for i in range(len(y))]\n",
    "    random.shuffle(mask)\n",
    "\n",
    "    X=X[mask]\n",
    "    y=y[mask]\n",
    "\n",
    "    X = np.reshape(X, (len(y),21*5))\n",
    "\n",
    "    print(\"X:\", X.shape)\n",
    "    print(\"y:\", y.shape)\n",
    "    return X, y-1\n",
    "\n",
    "# Separate all data files into four categories: go, stop, left, and right by threshold.\n",
    "# The default speed_threshold=5, angle_threshold=30\n",
    "def split(data, speed_threshold=5, angle_threshold=30, sign_threshold=0.5, data_size=200):\n",
    "    stop_full  = data[data[\"vehicle_speed\"]<=speed_threshold]\n",
    "\n",
    "    go = data[data[\"vehicle_speed\"]>speed_threshold]\n",
    "    go_full =  go[go[\"steering_angle_calculated\"]<=angle_threshold]\n",
    "\n",
    "    steer = go[go[\"steering_angle_calculated\"]>angle_threshold]\n",
    "    left_full  = steer[steer[\"steering_angle_sign\"]<=sign_threshold]\n",
    "    right_full = steer[steer[\"steering_angle_sign\"]>sign_threshold]\n",
    "    \n",
    "    go    = get_box(go_full[:data_size])\n",
    "    stop  = get_box(stop_full[:data_size])\n",
    "    left  = get_box(left_full[:data_size])\n",
    "    right = get_box(right_full[:data_size])\n",
    "    \n",
    "    return stop, go, left, right\n",
    "\n",
    "# Take out the bounding boxs, turning angle, speed and other data of all pictures from the data file.\n",
    "def get_box(fulltsv, padding=0):\n",
    "    maxBox = 21\n",
    "\n",
    "    header = [col for col in fulltsv]\n",
    "    header.remove('box')\n",
    "    \n",
    "    x_full = []\n",
    "    \n",
    "    label_dict = {'Car': 1,\n",
    "                 'VanSUV': 2,\n",
    "                 'Pedestrian': 3,\n",
    "                 'Trailer': 4,\n",
    "                 'Bus': 5,\n",
    "                 'Truck': 6,\n",
    "                 'Bicycle': 7,\n",
    "                 'MotorBiker': 8,\n",
    "                 'Motorcycle': 9,\n",
    "                 'Animal': 10,\n",
    "                 'UtilityVehicle': 11,\n",
    "                 'CaravanTransporter': 12,\n",
    "                 'EmergencyVehicle': 13,\n",
    "                 'Cyclist': 14}\n",
    "    \n",
    "    for index, row in fulltsv.iterrows():\n",
    "        x = []\n",
    "            \n",
    "        boxs = eval(row['box'])\n",
    "        for box in boxs[:maxBox]: # 生成x, 添加已有的box，box上限数量是maxBox\n",
    "            x.append(box['2d_bbox'] + [label_dict[box['class']]])\n",
    "\n",
    "        for i in range(maxBox - len(boxs)): # 填补空的box\n",
    "            x.append([padding,padding,padding,padding,padding])\n",
    "        \n",
    "        x_full.append(x)\n",
    "    return np.array(x_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN_Net(\n",
      "  (fc1): Linear(in_features=105, out_features=128, bias=True)\n",
      "  (dropout1): Dropout(p=0.25)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (dropout2): Dropout(p=0.25)\n",
      "  (fc3): Linear(in_features=64, out_features=36, bias=True)\n",
      "  (dropout3): Dropout(p=0.25)\n",
      "  (fc4): Linear(in_features=36, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Net, self).__init__()\n",
    "\n",
    "        # First 2D convolutional layer, taking in 1 input channel (image),\n",
    "        # outputting 32 convolutional features, with a square kernel size of 3\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        # Second 2D convolutional layer, taking in the 32 input layers,\n",
    "        # outputting 64 convolutional features, with a square kernel size of 3\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "\n",
    "        # Designed to ensure that adjacent pixels are either all 0s or all active\n",
    "        # with an input probability\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "\n",
    "        # First fully connected layer\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        # Second fully connected layer that outputs our 10 labels\n",
    "        self.fc2 = nn.Linear(128, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass data through conv1\n",
    "        x = self.conv1(x)\n",
    "        # Use the rectified-linear activation function over x\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Run max pooling over x\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        # Pass data through dropout1\n",
    "        x = self.dropout1(x)\n",
    "        # Flatten x with start_dim=1\n",
    "        x = torch.flatten(x, 1)\n",
    "        # Pass data through fc1\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # Apply softmax to x\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "class DNN_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(105, 128)\n",
    "        self.dropout1 = nn.Dropout(0.25) \n",
    "        \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.fc3 = nn.Linear(64, 36)\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.fc4 = nn.Linear(36, 4)        \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "my_nn = DNN_Net()\n",
    "print(my_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, flag):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device, dtype=torch.long)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if flag:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "def test(dataloader, model, loss_fn, flag):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device, dtype=torch.long)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    if flag:\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "def fit(model, train_dataloader, test_dataloader, epochs=100):\n",
    "    model = model.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "    epochs = 100\n",
    "    for t in range(epochs):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, False)\n",
    "        test(test_dataloader, model, loss_fn, False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# Use Kfold Train and Test in this function\n",
    "def process(X, y, n_splits=4):\n",
    "    cm_result = np.zeros((4,4))\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=False)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "    #     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train = torch.from_numpy(X_train)\n",
    "        y_train = torch.from_numpy(y_train)\n",
    "        X_test  = torch.from_numpy(X_test)\n",
    "        y_test  = torch.from_numpy(y_test)    \n",
    "\n",
    "        training_data = TensorDataset(X_train, y_train)\n",
    "        testing_data  = TensorDataset(X_test , y_test)\n",
    "        train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "        test_dataloader  = DataLoader(testing_data,  batch_size=64)\n",
    "        \n",
    "        model = DNN_Net()\n",
    "        model = fit(model, train_dataloader, test_dataloader)\n",
    "        \n",
    "        pred = model(X_test.to(device))\n",
    "#         y_pred = pred.argmax(1).detach().numpy()\n",
    "        y_pred = pred.argmax(1).detach().cpu().numpy()\n",
    "        y_test = y_test.numpy()\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        cm_rate = cm/cm.sum(axis=1)\n",
    "        cm_result += cm_rate\n",
    "    \n",
    "    correct = sum(y_pred==y_test)/len(y_test)\n",
    "    print(f\"Test Accuracy: {(100*correct):>0.1f}%\")\n",
    "    return cm_result/n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This experiment tried the influence of angle_threshold of 10, 20, 30...90 on the classification results.\n",
    "\n",
    "The classification accuracy is expressed in the form of a confusion matrix.  \n",
    "The diagonal line from top left to bottom right corresponds to the accuracy of the four categories. The four types are go, stop, left, and right.  \n",
    "The data in each row represents the probability that the data which is actually belonged to the row is classified and classified into the corresponding column by the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angle_threshold 10\n",
      "go, stop, left, right\n",
      "200 200 200 200\n",
      "X: (800, 105)\n",
      "y: (800,)\n",
      "Test Accuracy: 41.0%\n",
      "[[0.50025253 0.12082591 0.24501594 0.13461275]\n",
      " [0.17687015 0.46573084 0.2025837  0.16768295]\n",
      " [0.29662568 0.19569222 0.29508399 0.2279755 ]\n",
      " [0.27784365 0.19255051 0.24583091 0.28598122]]\n",
      "\n",
      "angle_threshold 20\n",
      "go, stop, left, right\n",
      "200 200 200 200\n",
      "X: (800, 105)\n",
      "y: (800,)\n",
      "Test Accuracy: 34.5%\n",
      "[[0.46941176 0.16427771 0.20454182 0.16370532]\n",
      " [0.22948802 0.38384093 0.20494998 0.17736936]\n",
      " [0.34633987 0.16151963 0.28045218 0.20821476]\n",
      " [0.2579085  0.20104049 0.27526411 0.26763943]]\n",
      "\n",
      "angle_threshold 30\n",
      "go, stop, left, right\n",
      "200 200 200 200\n",
      "X: (800, 105)\n",
      "y: (800,)\n",
      "Test Accuracy: 43.5%\n",
      "[[0.50309591 0.13892365 0.17974507 0.18768577]\n",
      " [0.09660827 0.54964539 0.1900932  0.18453901]\n",
      " [0.22746129 0.19743429 0.33220669 0.2676773 ]\n",
      " [0.25700691 0.14465999 0.26567708 0.34664612]]\n",
      "\n",
      "angle_threshold 40\n",
      "go, stop, left, right\n",
      "200 200 200 200\n",
      "X: (800, 105)\n",
      "y: (800,)\n",
      "Test Accuracy: 38.0%\n",
      "[[0.51174987 0.13867739 0.14659646 0.21750259]\n",
      " [0.17992751 0.41972135 0.17201618 0.24267612]\n",
      " [0.21671751 0.23108142 0.23874389 0.32298692]\n",
      " [0.24562721 0.1671186  0.16498779 0.42049275]]\n",
      "\n",
      "angle_threshold 50\n",
      "go, stop, left, right\n",
      "200 200 200 200\n",
      "X: (800, 105)\n",
      "y: (800,)\n",
      "Test Accuracy: 46.0%\n",
      "[[0.48977667 0.12451119 0.15991019 0.22568311]\n",
      " [0.18180165 0.51397234 0.14431391 0.16151077]\n",
      " [0.2389659  0.22555869 0.28095238 0.2609949 ]\n",
      " [0.20472554 0.16961541 0.21097013 0.41900794]]\n",
      "\n",
      "angle_threshold 60\n",
      "go, stop, left, right\n",
      "200 200 200 200\n",
      "X: (800, 105)\n",
      "y: (800,)\n",
      "Test Accuracy: 38.5%\n",
      "[[0.53958394 0.19058201 0.19372583 0.10136111]\n",
      " [0.15747154 0.54021164 0.15082907 0.16021189]\n",
      " [0.232728   0.22026455 0.36617686 0.20140571]\n",
      " [0.27340746 0.25931217 0.21638639 0.268845  ]]\n",
      "\n",
      "angle_threshold 70\n",
      "go, stop, left, right\n",
      "200 200 184 175\n",
      "X: (759, 105)\n",
      "y: (759,)\n",
      "Test Accuracy: 40.2%\n",
      "[[0.53213436 0.12211439 0.21714956 0.17726946]\n",
      " [0.15367711 0.46283385 0.25507886 0.18476464]\n",
      " [0.23507343 0.15182971 0.42786727 0.17450313]\n",
      " [0.23668921 0.1285779  0.31215884 0.27552553]]\n",
      "\n",
      "angle_threshold 80\n",
      "go, stop, left, right\n",
      "200 200 162 151\n",
      "X: (713, 105)\n",
      "y: (713,)\n",
      "Test Accuracy: 39.9%\n",
      "[[0.49546958 0.17628368 0.26288763 0.14642002]\n",
      " [0.2082672  0.52895008 0.2415061  0.11353736]\n",
      " [0.15228175 0.23732093 0.39065382 0.16215541]\n",
      " [0.20406746 0.16947943 0.26120577 0.23562249]]\n",
      "\n",
      "angle_threshold 90\n",
      "go, stop, left, right\n",
      "200 200 148 138\n",
      "X: (686, 105)\n",
      "y: (686,)\n",
      "Test Accuracy: 48.5%\n",
      "[[0.67093204 0.12470907 0.21635579 0.07562859]\n",
      " [0.2694421  0.53437831 0.1568127  0.12585022]\n",
      " [0.26216026 0.11710279 0.33700919 0.17208173]\n",
      " [0.30153852 0.10790839 0.23651758 0.16164137]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"full_info.tsv\", sep =\"\\t\")\n",
    "\n",
    "for i in range(1,10):\n",
    "    speed_threshold = 5\n",
    "    angle_threshold = i*10\n",
    "    sign_threshold = 0.5\n",
    "    \n",
    "    print(\"angle_threshold\", angle_threshold)\n",
    "    \n",
    "    data_size = 200\n",
    "    X, y = process_data(data, speed_threshold, angle_threshold, sign_threshold, data_size)\n",
    "    X = X.astype(np.float32) \n",
    "    y = y.astype(np.long) \n",
    "    \n",
    "    n_splits = 4\n",
    "    print(process(X, y, 4))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Analysis：\n",
    "The data in the third row and the third column and the data in the fourth row and fourth column of the confusion matrix correspond to the classification accuracy of the left class and the right class, respectively.  \n",
    "According to the results of different angle_threshold, we can believe that when angle_threshold ∈ [20,70], the classification accuracy of the two types does not change a lot.  \n",
    "When angle_threshold<20, the accuracy of the classification may deteriorate due to insufficient data discrimination.\n",
    "When angle_threshold>70, it may be that the total amount of data becomes smaller, and the final classification accuracy becomes worse.\n",
    "\n",
    "For angle_threshold ∈ [20,70], we can find that the accuracy rate is highest when angle_threshold=50, which is more appropriate angle_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expeiment Conclusion：\n",
    "50 should be a more appropriate angle_threshold. However, it does not improve the final accuracy rate much, and the accureate rate is still lower than 60%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
